{
  "hash": "a373bd3e51050cff492565c2fa8e185d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Initial Exploration\"\n---\n\n\n\n\n## Background\n\nThis is the initial exploration of Turkey Vulture kettling and migration behaviour\nabove Rocky Point on southern Vancouver Island. \n\n> Banding and observations start 1 hour before sunrise and commence for 6 hours. \n> Blanks and ****** indicate no data (NA), often because the banding station was not open at all due to rainy weather or closed early for similar reasons. \n> In addition, the station is on Department of National Defence land, \n> and blanks can arise when banders are excluded by DND. \n> Unfortunately, this applies to the entire year of 2007. \n> Zero values represent true zeros, the count was made but no vultures seen.\n\nData values are daily estimates \"of the greatest aggregation of vultures over Rocky Point that day during the station hours\".\n\n## Load & Clean Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"XX_functions.R\")  # Custom functions and packages\n```\n:::\n\n\n\n\n:::{.panel-tabset}\n\n### Load Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npeek <- read_excel(\"Data/Raw/TUVU DET 1998-2023 days excluded FINAL_DLK_2025-05-28.xlsx\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNew names:\n• `` -> `...1`\n• `` -> `...28`\n• `` -> `...29`\n• `` -> `...30`\n• `` -> `...31`\n• `` -> `...32`\n• `` -> `...33`\n• `` -> `...34`\n• `` -> `...35`\n```\n\n\n:::\n\n```{.r .cell-code}\nend <- which(peek$`day/year` == \"year\") - 1\n\nv <- read_excel(\"Data/Raw/TUVU DET 1998-2023 days excluded FINAL_DLK_2025-05-28.xlsx\", \n                na = c(\"\", \"******\"), n_max = end) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNew names:\n• `` -> `...27`\n• `` -> `...28`\n• `` -> `...29`\n• `` -> `...30`\n• `` -> `...31`\n```\n\n\n:::\n:::\n\n\n\n\n### Quick Check\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(v)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 31\n  `day/year`          `1998` `1999` `2000` `2001` `2002` `2003` `2004` `2005`\n  <dttm>               <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 2023-07-23 00:00:00      4     NA      2      4      3      4      3      3\n2 2023-07-24 00:00:00      7     NA      0      3      4      5      3      4\n3 2023-07-25 00:00:00      4      6      2      3      7      4      5      6\n4 2023-07-26 00:00:00      0      4      0      2      6      5      4      6\n5 2023-07-27 00:00:00      0      7     NA      9      5      1      1      1\n6 2023-07-28 00:00:00      1      4     NA     10      7      6      1      8\n# ℹ 22 more variables: `2006` <dbl>, `2008` <dbl>, `2009` <dbl>, `2010` <dbl>,\n#   `2011` <dbl>, `2012` <dbl>, `2013` <dbl>, `2014` <dbl>, `2015` <dbl>,\n#   `2016` <dbl>, `2017` <dbl>, `2018` <dbl>, `2019` <dbl>, `2020` <dbl>,\n#   `2021` <dbl>, `2022` <dbl>, `2023` <dbl>, ...27 <lgl>, ...28 <lgl>,\n#   ...29 <lgl>, ...30 <lgl>, ...31 <chr>\n```\n\n\n:::\n\n```{.r .cell-code}\ntail(v)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 31\n  `day/year`          `1998` `1999` `2000` `2001` `2002` `2003` `2004` `2005`\n  <dttm>               <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 2023-10-16 00:00:00      0     NA      0     NA     25     NA    120      5\n2 2023-10-17 00:00:00     NA     NA      4     NA     26     NA     NA     NA\n3 2023-10-18 00:00:00     12     NA      4     NA     14      6     26     10\n4 2023-10-19 00:00:00     NA     18     NA     NA      8     NA     NA     NA\n5 2023-10-20 00:00:00     NA     10     NA     NA     17     NA     NA     NA\n6 2023-10-21 00:00:00     NA     NA     NA     NA      9     NA     NA     NA\n# ℹ 22 more variables: `2006` <dbl>, `2008` <dbl>, `2009` <dbl>, `2010` <dbl>,\n#   `2011` <dbl>, `2012` <dbl>, `2013` <dbl>, `2014` <dbl>, `2015` <dbl>,\n#   `2016` <dbl>, `2017` <dbl>, `2018` <dbl>, `2019` <dbl>, `2020` <dbl>,\n#   `2021` <dbl>, `2022` <dbl>, `2023` <dbl>, ...27 <lgl>, ...28 <lgl>,\n#   ...29 <lgl>, ...30 <lgl>, ...31 <chr>\n```\n\n\n:::\n:::\n\n\n\n:::\n\n:::{.panel-tabset}\n\n### Quick Clean\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nv <- rename(v, date = \"day/year\") %>%\n  select(matches(\"date|\\\\d{4}\")) %>%\n  assert(is.numeric, -\"date\") # make sure we get only numeric data, not summaries\n```\n:::\n\n\n\n\n### Quick Check\nExpect 2023 for all years, as original data doesn't include year and R *must* have\na year (this is corrected below).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nv\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 91 × 26\n   date                `1998` `1999` `2000` `2001` `2002` `2003` `2004` `2005`\n   <dttm>               <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n 1 2023-07-23 00:00:00      4     NA      2      4      3      4      3      3\n 2 2023-07-24 00:00:00      7     NA      0      3      4      5      3      4\n 3 2023-07-25 00:00:00      4      6      2      3      7      4      5      6\n 4 2023-07-26 00:00:00      0      4      0      2      6      5      4      6\n 5 2023-07-27 00:00:00      0      7     NA      9      5      1      1      1\n 6 2023-07-28 00:00:00      1      4     NA     10      7      6      1      8\n 7 2023-07-29 00:00:00      0      5      0      2      6      1      3      1\n 8 2023-07-30 00:00:00      3     34      3      0      2      1      3      4\n 9 2023-07-31 00:00:00      4     11      4      8      2      7      2      3\n10 2023-08-01 00:00:00      6      5      0      2      6      5      3      4\n# ℹ 81 more rows\n# ℹ 17 more variables: `2006` <dbl>, `2008` <dbl>, `2009` <dbl>, `2010` <dbl>,\n#   `2011` <dbl>, `2012` <dbl>, `2013` <dbl>, `2014` <dbl>, `2015` <dbl>,\n#   `2016` <dbl>, `2017` <dbl>, `2018` <dbl>, `2019` <dbl>, `2020` <dbl>,\n#   `2021` <dbl>, `2022` <dbl>, `2023` <dbl>\n```\n\n\n:::\n:::\n\n\n\n:::\n\n\n:::{.panel-tabset}\n### Re-arrange\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nv <- v |>\n  mutate(`2007` = NA) |>  # Add missing year for completeness\n  relocate(\"2007\", .before = \"2008\") |>\n  pivot_longer(-date, names_to = \"year\", values_to = \"count\")\n\nyear(v$date) <- as.integer(v$year)  # Fix years for each date\n\nv <- mutate(v, date = as_date(date), doy = yday(date))\n```\n:::\n\n\n\n\n### Quick Check\nCorrect year on all dates now, and verify a couple of random dates.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nv %>%\n  verify(is.na(count[date == \"1999-07-23\"])) %>%\n  verify(count[date == \"2006-08-06\"] == 7) %>%\n  verify(count[date == \"2020-09-26\"] == 50) %>%\n  verify(count[date == \"2023-10-14\"] == 54)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2,366 × 4\n   date       year  count   doy\n   <date>     <chr> <dbl> <dbl>\n 1 1998-07-23 1998      4   204\n 2 1999-07-23 1999     NA   204\n 3 2000-07-23 2000      2   205\n 4 2001-07-23 2001      4   204\n 5 2002-07-23 2002      3   204\n 6 2003-07-23 2003      4   204\n 7 2004-07-23 2004      3   205\n 8 2005-07-23 2005      3   204\n 9 2006-07-23 2006      4   204\n10 2007-07-23 2007     NA   204\n# ℹ 2,356 more rows\n```\n\n\n:::\n:::\n\n\n\n:::\n\n## Quick look at the data\n\n**Too see full screen: Right-click and select \"Open Image in New Tab\" (or similar)**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(v, aes(x = doy, y = count, group = year, colour = year)) +\n  theme_bw() +\n  geom_point(na.rm = TRUE) +\n  stat_smooth(method = \"gam\", formula = y ~ s(x, k = 20), \n              method.args = list(method = \"REML\", family = \"nb\"), na.rm = TRUE, \n              level = 0.95) +\n  facet_wrap(~year, scales = \"free\") +\n  scale_colour_viridis_d()\n```\n\n::: {.cell-output-display}\n![](01_initial_exploration_files/figure-html/unnamed-chunk-8-1.png){width=1536}\n:::\n:::\n\n\n\n\nOmit 1998 because missing almost all of the second half of the migration period.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nv <- filter(v, year != 1998)\n```\n:::\n\n\n\n\nSave this formatted data for later use\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(v, \"Data/Datasets/vultures_clean_2023.csv\")\n```\n:::\n\n\n\n\n\n## Questions\n\n1. Has the timing of kettle formation and migration has changed over the years?\n    - If so, what is the pattern of change? (Direction and magnitude of change)\n    - If not, document temporal distribution of numbers\n\n2. Has the number of birds in the kettles changed over time?\n    - may indicate population trends\n    - complicated by accumulating birds over days when the weather conditions are not suitable for passing over the strait\n    - potentially look at weather effects...\n\n## Metrics to assess\n\nTo answer these questions we need to summarize the counts into specific metrics\nrepresenting the timing of migration.\n\nSpecifically, we would like to calculate the\n\n- dates of 5%, 25%, 50%, 75%, and 95% of the kettle numbers\n- duration of passage  - No. days between 5% and 95%\n- duration of peak passage - No. days between 25% and 75%\n\nPopulation size (no. vultures in aggregations)\n\n- maximum\n- cumulative\n- number at peak passage (max? range? median?)\n- mean/median number of locals\n\nOf these, the most important starting metrics are the \n**dates of 5%, 25%, 50%, 75%, and 95% of the kettle numbers**. \nThese dates will define migration phenology as well as local vs. migrating counts.\nAll other calculations can be performed using these values and the raw data.\n\n\n## How to calculate dates of passage?\n\n- Don suggested following methodology from Allcock et al 2022\n  - \"fit a curve to the data for each year and use it to estimate ...\"\n- Allcock et al 2022 \"modelled optimal Gaussian functions to describe the migration\n  phenology for each species – year combination in our dataset using\n  Markhov Chain Monte Carlo (MCMC) techniques\".\n- They say that \"Gaussian functions ... often outperform General Additive Models (Linden et al., 2016)\"\n\n**I like this approach in general, but I'm not convinced that we can't/shouldn't use GAMs.**\n\nIn [Linden et al.](https://onlinelibrary.wiley.com/doi/epdf/10.1111/jav.00994), \nthey restricted the GAM models' effective degrees of freedom (which isn't common, usually they are determined by the modelling procedure) and note that if they didn't restrict them, \n\"GAMs would have been preferred in 73% of the cases\". \n\nThe argument for restricting GAMS was to make the comparison among models possible as the \n\"estimation of [effective] degrees of freedom [in a GAM] is similar to a model selection procedure\".\nThis would have invalidated their use of the information theoretic approach for model comparison.\n\nI still think we should use GAMs, because \n\n1. We are using this to calculate metrics and as long as the model fits the data, is consistent and replicable, it doesn't really matter how we get there (i.e. there's no reason to not use\n  the best GAM method with built-in model selection).\n2. We are looking at a single species and so can assess each year to make sure it looks right.\n3. I am familiar with GAMs, but have no experience with MCMC techniques to model Gaussian functions.\n4. I don't think that Linden et al. really demonstrated that GAMs are 'bad' to use.\n\n### Steffi's suggested approach\n\nWe use GAMs to model each year individually. \nFrom the predicted data we calculate the cumulative counts and the points at \nwhich these counts hit 5%, 25%, 75%, 95% of the total \n(I think this is what Allcock et al mean by 'bird-days'?).\n\nHowever, we will need to think about how to handle the resident birds, \nas they may artificially inflate the cumulative counts prior to migration. \n\n\n## Using GAM based appraoch {#gam}\n\nFor illustration and exploration of this approach, we'll look at 2000. \n\n::: {.panel-tabset}\n### Example GAM - 2000\n\n- Negative binomial model fits the count data with overdispersion\n- Use Restricted Maximum Likelihood (\"Most likely to give you reliable, stable results\"[^1])\n- We smooth (`s()`) over `doy` (day of year) to account for non-linear migration patterns\n- We set `k = 10` (up to 10 basis functions; we want enough to make sure we capture the patterns, but too many will slow things down).\n\n[^1]: https://noamross.github.io/gams-in-r-course/chapter1\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- gam(count ~ s(doy, k = 10), data = filter(v, year == 2000), \n         method = \"REML\", family = \"nb\")\nplot(g, shade = TRUE, trans = exp, residuals = TRUE, pch = 20, \n     shift = coef(g)[1])\n```\n\n::: {.cell-output-display}\n![](01_initial_exploration_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\n### Model summary\nNot really necessary for us to evaluate, but the `s(doy)` value indicates that we have a signifcant\npattern, and the fact that the `edf` value is less than our `k = 10`, is good.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(g)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFamily: Negative Binomial(1.129) \nLink function: log \n\nFormula:\ncount ~ s(doy, k = 10)\n\nParametric coefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   2.3393     0.1207   19.38   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n         edf Ref.df Chi.sq p-value    \ns(doy) 5.475  6.616  175.5  <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.391   Deviance explained = 71.3%\n-REML =  271.2  Scale est. = 1         n = 76\n```\n\n\n:::\n:::\n\n\n\n\n\n### Model evaluation\nQuick checks to ensure model is valid.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\np0 <- par(mfrow = c(2,2))\ngam.check(g, pch = 19, cex = 0.5)\n```\n\n::: {.cell-output-display}\n![](01_initial_exploration_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMethod: REML   Optimizer: outer newton\nfull convergence after 4 iterations.\nGradient range [8.674563e-10,1.084888e-07]\n(score 271.1993 & scale 1).\nHessian positive definite, eigenvalue range [2.264941,28.62155].\nModel rank =  10 / 10 \n\nBasis dimension (k) checking results. Low p-value (k-index<1) may\nindicate that k is too low, especially if edf is close to k'.\n\n         k'  edf k-index p-value\ns(doy) 9.00 5.48    0.96    0.62\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\npar(p0)\n\ns <- DHARMa::simulateResiduals(g, plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](01_initial_exploration_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n:::\n\n\n\n:::\n\n### Calculating dates of passage\n\nFirst create data set of predicted GAM model outputs across the entire date range.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoy <- min(g$model$doy):max(g$model$doy)\n\np <- predict(g, newdata = list(doy = doy), type = \"response\", se.fit = TRUE)\nd <- data.frame(doy = doy, count = p$fit, se = p$se) |>\n  mutate(ci99_upper = count + se * 2.58,\n         ci99_lower = count - se * 2.58)\n```\n:::\n\n\n\n\nNext we'll calculate percentiles based on cumulative counts. \nBut there are several ways we can do this, depending how we want to account for \nresident vultures.\n\n- Option 1: We do nothing\n- Option 2: We use the model's CI 99% to find a threshold date before which we assume all observations are of local, resident vultures, after which is migration. We would then calculate cumulative counts only on data after this threshold)[^2]\n- Option 3: We calculate the median number of residents and simply subtract that from \nall counts before calculating our cumulative counts.\n\n[^2]: Similar to a method I used in a paper with Matt Reudink on Bluebirds and also \none on Swifts (companion to the one you referenced). We used this to calculate a \nthreshold for latitude to define the start and end of migration by population postition\nrather than counts, though. \n\n### Option 1: Do not omit resident vultures\n\n- Use entire date range\n- No threshold cutoff\n- No subtraction of local counts\n- Calculate local counts from predicted data before Day 240\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nd_sum <- mutate(d, count_sum = cumsum(count))\n\ndts <- calc_dates(d_sum)\ndts_overall <- mutate(dts, type = \"Option 1: No Adjustments\")\n\nresidents <- d |>\n  filter(doy < 240) |>\n  summarize(res_pop_min = min(count), res_pop_max = max(count), \n            res_pop_median = median(count), res_pop_mean = mean(count)) |>\n  mutate(across(everything(), \\(x) round(x, 1)))\n\ng1 <- plot_cum_explore(d_sum = d_sum, dts = dts)\ng2 <- plot_model_explore(d_raw = g$model, d_pred = d, dts = dts, residents, resident_date = 240) +\n  labs(caption = \"Local count stats calculated up to Day 240\")\ng_opt1 <- g1 / g2 + plot_annotation(title = \"Option 1: No adjustments\")\n```\n:::\n\n\n\n\n### Option 2: Use a count threshold to omit dates with resident vultures\n\n- Use the *minimum* value of the *upper limit* of the CI 99% to calculate a \n  cutoff **threshold** (only consider dates < 270 to avoid the end of migration tailing off)\n- The first date prior to migration which crosses this threshold *into migration* \n  (i.e. avoids little blips up and down early in the year) is used as the\n  **threshold**\n- The data is filtered to include only dates *on or after this threshold*\n- Then the percentiles are calculated based on cumulative counts in this\n  subset\n  \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthresh <- filter(d, doy < 270) |> # Only consider pre-migration\n  arrange(desc(doy)) |>\n  filter(count <= min(ci99_upper)) |>\n  slice(1) |>\n  pull(doy)\nthresh\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 228\n```\n\n\n:::\n:::\n\n\n\n\n> #### What is the min of the upper limit of the CI 99%?!?!?\n>\n> In the image below...\n> \n> - the Grey ribbon represents the 99% Confidence Interval around the GAM model (grey line)\n> - the upper limit of this *ribbon* is the upper limit of the 99% CI\n> - the *minimum* of this value is the area on the figure where the upper edge of the \n>   ribbon is at it's lowest value (large black point)\n> - in this year/model, it's occurs on the first day\n>\n> **How do we use this value?**\n>\n> - the first value in the model (grey line) to cross this limit (dashed black line),\n>   identifies our threshold date (red dashed line)\n> - we then use only the dates *after* this threshold to calculate migration metrics\n> - we then use only the dates *before* this threshold to calculate local counts\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# g1 <- ggplot(data = d, mapping = aes(x = doy, y = count)) +\n#   theme_bw() +\n#   geom_ribbon(aes(ymin = ci99_lower, ymax = ci99_upper), fill = \"grey50\", alpha = 0.5) +\n#   geom_point(data = g$model) +\n#   geom_line() +\n#   coord_cartesian(xlim = c(204, 270)) +\n#   labs(title = \"Look only at beginning of migration\")\n\ng2 <- ggplot(data = d, mapping = aes(x = doy, y = count)) +\n  theme_bw() +\n  theme(legend.position = c(0.3, 0.85), legend.title = element_blank()) +\n  geom_ribbon(aes(ymin = ci99_lower, ymax = ci99_upper), fill = \"grey50\", alpha = 0.3) +\n  geom_point(data = g$model, colour = \"grey40\") +\n  geom_line(colour = \"grey60\") +\n  coord_cartesian(xlim = c(204, 245), ylim = c(-5, 40)) +\n  geom_point(x = d$doy[d$ci99_upper == min(d$ci99_upper)], \n             y = min(d$ci99_upper), size = 4, aes(colour = \"Day with min 99% CI\"),\n             inherit.aes = FALSE) +\n  geom_hline(linetype = 2,\n             aes(yintercept = min(d$ci99_upper), colour = \"Min of upper 99% CI\")) +\n  geom_vline(linetype = 2,\n             aes(xintercept = thresh, colour = \"Threshold\\n(first date consistently\\nabove min of upper 99% CI)\")) +\n  scale_colour_manual(values = c(\"black\", \"black\", \"red\")) +\n  guides(colour = guide_legend(override.aes = list(shape = c(19, 0, 0), size = c(3, 0, 0), linewidth = c(0, 0.3, 0.3), linetype = c(\"solid\", \"dashed\", \"dashed\")))) +\n  labs(title = \"Find thresholds based on local counts\", \n       subtitle = \"Figure is model plot 'zoomed' into early season\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\ng2\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in geom_point(x = d$doy[d$ci99_upper == min(d$ci99_upper)], y = min(d$ci99_upper), : All aesthetics have length 1, but the data has 88 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Use of `d$ci99_upper` is discouraged.\nℹ Use `ci99_upper` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](01_initial_exploration_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nd_sum <- filter(d, doy >= thresh) |>\n  mutate(count_sum = cumsum(count))\n\ndts <- calc_dates(d_sum)\ndts_overall <- bind_rows(dts_overall, \n                         mutate(dts, type = \"Option 2: Threshold\"))\n\nresidents <- d |>\n  filter(doy < thresh) |>\n  summarize(res_pop_min = min(count), res_pop_max = max(count), \n            res_pop_median = median(count), res_pop_mean = mean(count)) |>\n  mutate(across(everything(), \\(x) round(x, 1)))\n\n\ng1 <- plot_cum_explore(d_sum, dts) +\n  geom_vline(xintercept = thresh, colour = \"red\", linetype = \"dotted\") +\n  annotate(\"text\", label = \"Threshold\", x = thresh, y = 1000)\ng2 <- plot_model_explore(d_raw = g$model, d_pred = d, dts = dts, residents, resident_date = thresh) +\n  labs(caption = paste0(\"Resident count stats calculated up to threshold date, \", thresh))\n  \ng_opt2 <- g1 / g2 + plot_annotation(title = \"Option 2: Use only dates after threshold\")\n```\n:::\n\n\n\n\n### Option 3: Subtract the median resident count from all observations {#option-3}\n- Use entire date range\n- No threshold cutoff\n- Subtract the median resident count from the predicted observations, prior to \n  calculating the cumulative counts\n- Calculate resident counts from predicted data before Day 240\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nresidents <- d |>\n  filter(doy < 240) |>\n  summarize(res_pop_min = min(count), res_pop_max = max(count), \n            res_pop_median = median(count), res_pop_mean = mean(count)) |>\n  mutate(across(everything(), \\(x) round(x, 1)))\n\nd_sum <- mutate(d, \n                count = count - residents$res_pop_median,\n                count_sum = cumsum(count))\n\ndts <- calc_dates(d_sum)\ndts_overall <- bind_rows(dts_overall, \n                         mutate(dts, type = \"Option 3: Subtraction\"))\n\ng1 <- plot_cum_explore(d_sum = d_sum, dts = dts) +\n  annotate(\"text\", x = 225, y = 1000,\n           label = paste0(\"Remove \", \n                          residents$res_pop_median, \n                          \" from all counts\\nbefore calcuating cumuative sum\"))\ng2 <- plot_model_explore(d_raw = g$model, d_pred = d, dts = dts, residents, resident_date = 240) +\n  labs(caption = \"Local count stats calculated up to Day 240\")\ng_opt3 <- g1 / g2 + plot_annotation(title = \"Option 3: Subtract median first\")\n```\n:::\n\n\n\n\n### Comparing our options\n\nIn each figure the red dots represent the 5%, 25%, 50%, 75% and 95% dates calculated\nbased on the cumulative counts (top figure, dotted lines show the percentiles). \n\nThe bottom figure shows the raw counts, with the GAM model overlaid, the pink\nwindows indicate 5%-95% and 25%-75% date ranges. The arrow on the left indicates\nwhich predicted values were included in the local count statistics. \n\nNote that the only two things that really change in this example are the \ninitial 5% date (becomes increasingly later with each option) and the calculation\nof the \"local\" population statistics (because in Option 1 and Option 2, they're\nbased on the same set of data, but in Option 2, we use a threshold to define\nbefore and after the expected start of migration.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng_opt1\n```\n\n::: {.cell-output-display}\n![](01_initial_exploration_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\ng_opt2\n```\n\n::: {.cell-output-display}\n![](01_initial_exploration_files/figure-html/unnamed-chunk-20-2.png){width=672}\n:::\n\n```{.r .cell-code}\ng_opt3\n```\n\n::: {.cell-output-display}\n![](01_initial_exploration_files/figure-html/unnamed-chunk-20-3.png){width=672}\n:::\n:::\n\n\n\n\n\nHowever in this example (and in many that I've looked at), this only really\naffects the first, 5%, Date value.\n\nHere are the dates calculated for each percentiles using the different methods \nin this example.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndts_overall |>\n  select(-contains(\"count\")) |>\n  pivot_wider(names_from = \"perc\", values_from = \"doy_passage\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 6\n  type                       p05   p25   p50   p75   p95\n  <chr>                    <dbl> <dbl> <dbl> <dbl> <dbl>\n1 Option 1: No Adjustments   247   262   268   273   281\n2 Option 2: Threshold        250   262   268   273   281\n3 Option 3: Subtraction      253   263   268   273   281\n```\n\n\n:::\n:::\n\n\n\n\n\n### Steffi's suggested approach\n\n**I suggest we use Option 3: Subtracting the median local numbers.**\n\nI think that Option 1 gives us an artifically early start to migration as it\nstarts cumulating counts over resident bird observations.\n\nI think that Option 2 works, but is potentially overly complicated.\nI'm also not convinced that it completely avoids the issue of resident birds. \n\nOn the other hand I find Option 3\n\n- Reasonable\n- Easy to explain\n- Visually, it looks the most 'right' (to me at any rate)\n- It seems to result in more conservative numbers\n\n\nOther options\n\n- We could also just not use the 5% and 95% metrics\n- I could run all three methods on the full data set and we could check them \n  all together. \n\n\n\n\n## Reproducibility\n\n:::{.callout-note collapse=true}\n### Session Info\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndevtools::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.5.0 (2025-04-11)\n os       Ubuntu 24.04.2 LTS\n system   x86_64, linux-gnu\n ui       X11\n language en_CA:en_US:en\n collate  en_CA.UTF-8\n ctype    en_CA.UTF-8\n tz       America/Winnipeg\n date     2025-06-06\n pandoc   3.4 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/x86_64/ (via rmarkdown)\n quarto   1.6.39 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package       * version date (UTC) lib source\n P assertr       * 3.0.1   2023-11-23 [?] CRAN (R 4.5.0)\n P backports       1.5.0   2024-05-23 [?] CRAN (R 4.5.0)\n P bit             4.6.0   2025-03-06 [?] CRAN (R 4.5.0)\n P bit64           4.6.0-1 2025-01-16 [?] CRAN (R 4.5.0)\n P boot            1.3-31  2024-08-28 [?] CRAN (R 4.4.2)\n P broom         * 1.0.8   2025-03-28 [?] CRAN (R 4.5.0)\n P cachem          1.1.0   2024-05-16 [?] CRAN (R 4.5.0)\n P cellranger      1.1.0   2016-07-27 [?] CRAN (R 4.5.0)\n P class           7.3-23  2025-01-01 [?] CRAN (R 4.4.2)\n P classInt        0.4-11  2025-01-08 [?] CRAN (R 4.5.0)\n P cli             3.6.5   2025-04-23 [?] CRAN (R 4.5.0)\n P codetools       0.2-20  2024-03-31 [?] CRAN (R 4.4.0)\n P crayon          1.5.3   2024-06-20 [?] CRAN (R 4.5.0)\n P DBI             1.2.3   2024-06-02 [?] CRAN (R 4.5.0)\n P devtools        2.4.5   2022-10-11 [?] CRAN (R 4.5.0)\n P DHARMa        * 0.4.7   2024-10-18 [?] CRAN (R 4.5.0)\n P digest          0.6.37  2024-08-19 [?] CRAN (R 4.5.0)\n P doParallel      1.0.17  2022-02-07 [?] CRAN (R 4.5.0)\n P dplyr         * 1.1.4   2023-11-17 [?] CRAN (R 4.5.0)\n P e1071           1.7-16  2024-09-16 [?] CRAN (R 4.5.0)\n P ellipsis        0.3.2   2021-04-29 [?] CRAN (R 4.5.0)\n P evaluate        1.0.3   2025-01-10 [?] CRAN (R 4.5.0)\n P farver          2.1.2   2024-05-13 [?] CRAN (R 4.5.0)\n P fastmap         1.2.0   2024-05-15 [?] CRAN (R 4.5.0)\n P foreach         1.5.2   2022-02-02 [?] CRAN (R 4.5.0)\n P fs              1.6.6   2025-04-12 [?] CRAN (R 4.5.0)\n P gamm4           0.2-7   2025-04-22 [?] CRAN (R 4.5.0)\n P gap             1.6     2024-08-27 [?] CRAN (R 4.5.0)\n P gap.datasets    0.0.6   2023-08-25 [?] CRAN (R 4.5.0)\n P generics        0.1.4   2025-05-09 [?] CRAN (R 4.5.0)\n P GGally          2.2.1   2024-02-14 [?] CRAN (R 4.5.0)\n P ggplot2       * 3.5.2   2025-04-09 [?] CRAN (R 4.5.0)\n P ggspatial     * 1.1.9   2023-08-17 [?] CRAN (R 4.5.0)\n P ggstats         0.9.0   2025-03-10 [?] CRAN (R 4.5.0)\n P ggthemes      * 5.1.0   2024-02-10 [?] CRAN (R 4.5.0)\n P glue            1.8.0   2024-09-30 [?] CRAN (R 4.5.0)\n P gridExtra       2.3     2017-09-09 [?] CRAN (R 4.5.0)\n P gt            * 1.0.0   2025-04-05 [?] CRAN (R 4.5.0)\n P gtable          0.3.6   2024-10-25 [?] CRAN (R 4.5.0)\n P hms             1.1.3   2023-03-21 [?] CRAN (R 4.5.0)\n P htmltools       0.5.8.1 2024-04-04 [?] CRAN (R 4.5.0)\n P htmlwidgets     1.6.4   2023-12-06 [?] CRAN (R 4.5.0)\n P httpuv          1.6.16  2025-04-16 [?] CRAN (R 4.5.0)\n P httr            1.4.7   2023-08-15 [?] CRAN (R 4.5.0)\n P iterators       1.0.14  2022-02-05 [?] CRAN (R 4.5.0)\n P jsonlite        2.0.0   2025-03-27 [?] CRAN (R 4.5.0)\n P KernSmooth      2.23-26 2025-01-01 [?] CRAN (R 4.4.2)\n P knitr           1.50    2025-03-16 [?] CRAN (R 4.5.0)\n P labeling        0.4.3   2023-08-29 [?] CRAN (R 4.5.0)\n P later           1.4.2   2025-04-08 [?] CRAN (R 4.5.0)\n P lattice         0.22-5  2023-10-24 [?] CRAN (R 4.3.3)\n P lifecycle       1.0.4   2023-11-07 [?] CRAN (R 4.5.0)\n P lme4            1.1-37  2025-03-26 [?] CRAN (R 4.5.0)\n P lubridate     * 1.9.4   2024-12-08 [?] CRAN (R 4.5.0)\n P magrittr        2.0.3   2022-03-30 [?] CRAN (R 4.5.0)\n P MASS            7.3-65  2025-02-28 [?] CRAN (R 4.4.3)\n P Matrix          1.7-3   2025-03-11 [?] CRAN (R 4.4.3)\n P matrixStats     1.5.0   2025-01-07 [?] CRAN (R 4.5.0)\n P memoise         2.0.1   2021-11-26 [?] CRAN (R 4.5.0)\n P mgcv          * 1.9-3   2025-04-04 [?] CRAN (R 4.5.0)\n P mgcViz        * 0.2.0   2025-04-11 [?] CRAN (R 4.5.0)\n P mime            0.13    2025-03-17 [?] CRAN (R 4.5.0)\n P miniUI          0.1.2   2025-04-17 [?] CRAN (R 4.5.0)\n P minqa           1.2.8   2024-08-17 [?] CRAN (R 4.5.0)\n P moments       * 0.14.1  2022-05-02 [?] CRAN (R 4.5.0)\n P nlme          * 3.1-168 2025-03-31 [?] CRAN (R 4.4.3)\n P nloptr          2.2.1   2025-03-17 [?] CRAN (R 4.5.0)\n P openxlsx      * 4.2.8   2025-01-25 [?] CRAN (R 4.5.0)\n P patchwork     * 1.3.0   2024-09-16 [?] CRAN (R 4.5.0)\n P pillar          1.10.2  2025-04-05 [?] CRAN (R 4.5.0)\n P pkgbuild        1.4.7   2025-03-24 [?] CRAN (R 4.5.0)\n P pkgconfig       2.0.3   2019-09-22 [?] CRAN (R 4.5.0)\n P pkgload         1.4.0   2024-06-28 [?] CRAN (R 4.5.0)\n P plyr            1.8.9   2023-10-02 [?] CRAN (R 4.5.0)\n P profvis         0.4.0   2024-09-20 [?] CRAN (R 4.5.0)\n P promises        1.3.2   2024-11-28 [?] CRAN (R 4.5.0)\n P proxy           0.4-27  2022-06-09 [?] CRAN (R 4.5.0)\n P purrr         * 1.0.4   2025-02-05 [?] CRAN (R 4.5.0)\n P qgam          * 2.0.0   2025-04-10 [?] CRAN (R 4.5.0)\n P R6              2.6.1   2025-02-15 [?] CRAN (R 4.5.0)\n P rbibutils       2.3     2024-10-04 [?] CRAN (R 4.5.0)\n P RColorBrewer    1.1-3   2022-04-03 [?] CRAN (R 4.5.0)\n P Rcpp            1.0.14  2025-01-12 [?] CRAN (R 4.5.0)\n P Rdpack          2.6.4   2025-04-09 [?] CRAN (R 4.5.0)\n P readr         * 2.1.5   2024-01-10 [?] CRAN (R 4.5.0)\n P readxl        * 1.4.5   2025-03-07 [?] CRAN (R 4.5.0)\n P reformulas      0.4.1   2025-04-30 [?] CRAN (R 4.5.0)\n P remotes         2.5.0   2024-03-17 [?] CRAN (R 4.5.0)\n P renv            1.1.4   2025-03-20 [?] CRAN (R 4.5.0)\n P rlang           1.1.6   2025-04-11 [?] CRAN (R 4.5.0)\n P rmarkdown       2.29    2024-11-04 [?] CRAN (R 4.5.0)\n P rnaturalearth * 1.0.1   2023-12-15 [?] CRAN (R 4.5.0)\n P rstudioapi      0.17.1  2024-10-22 [?] CRAN (R 4.5.0)\n P scales          1.4.0   2025-04-24 [?] CRAN (R 4.5.0)\n P sessioninfo     1.2.3   2025-02-05 [?] CRAN (R 4.5.0)\n P sf            * 1.0-20  2025-03-24 [?] CRAN (R 4.5.0)\n P shiny           1.10.0  2024-12-14 [?] CRAN (R 4.5.0)\n P stringi         1.8.7   2025-03-27 [?] CRAN (R 4.5.0)\n P stringr       * 1.5.1   2023-11-14 [?] CRAN (R 4.5.0)\n P terra           1.8-42  2025-04-02 [?] CRAN (R 4.5.0)\n P tibble          3.2.1   2023-03-20 [?] CRAN (R 4.5.0)\n P tidyr         * 1.3.1   2024-01-24 [?] CRAN (R 4.5.0)\n P tidyselect      1.2.1   2024-03-11 [?] CRAN (R 4.5.0)\n P timechange      0.3.0   2024-01-18 [?] CRAN (R 4.5.0)\n P tzdb            0.5.0   2025-03-15 [?] CRAN (R 4.5.0)\n P units           0.8-7   2025-03-11 [?] CRAN (R 4.5.0)\n P urlchecker      1.0.1   2021-11-30 [?] CRAN (R 4.5.0)\n P usethis         3.1.0   2024-11-26 [?] CRAN (R 4.5.0)\n P utf8            1.2.5   2025-05-01 [?] CRAN (R 4.5.0)\n P vctrs           0.6.5   2023-12-01 [?] CRAN (R 4.5.0)\n P viridis         0.6.5   2024-01-29 [?] CRAN (R 4.5.0)\n P viridisLite     0.4.2   2023-05-02 [?] CRAN (R 4.5.0)\n P vroom           1.6.5   2023-12-05 [?] CRAN (R 4.5.0)\n P withr           3.0.2   2024-10-28 [?] CRAN (R 4.5.0)\n P xfun            0.52    2025-04-02 [?] CRAN (R 4.5.0)\n P xml2            1.3.8   2025-03-14 [?] CRAN (R 4.5.0)\n P xtable          1.8-4   2019-04-21 [?] CRAN (R 4.5.0)\n P yaml            2.3.10  2024-07-26 [?] CRAN (R 4.5.0)\n P zip             2.3.2   2025-02-01 [?] CRAN (R 4.5.0)\n\n [1] /home/steffi/Projects/vulture_migration/renv/library/linux-ubuntu-noble/R-4.5/x86_64-pc-linux-gnu\n [2] /home/steffi/.cache/R/renv/sandbox/linux-ubuntu-noble/R-4.5/x86_64-pc-linux-gnu/9a444a72\n\n * ── Packages attached to the search path.\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n\n:::\n\n",
    "supporting": [
      "01_initial_exploration_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}